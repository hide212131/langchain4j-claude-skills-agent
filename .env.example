# LLM 設定サンプル
# LLM_PROVIDER は mock|openai を指定します。未指定時は mock になります。
LLM_PROVIDER=mock

# OpenAI Official SDK を使う場合に設定します。mock のままなら空で構いません。
OPENAI_API_KEY=
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4.1

# 可視化エクスポート設定（Phase2）
# EXPORTER は none|otlp を指定。未設定時は none。
EXPORTER=none
# OTLP 送信先エンドポイント
# - gRPC 例: http://localhost:4317
# - LangFuse(self-host) OTLP/HTTP 例: http://localhost:3000/api/public/otel
OTEL_EXPORTER_OTLP_ENDPOINT=
# OTLP 追加ヘッダ（例: authorization=Bearer token,api-key=xxx）
OTEL_EXPORTER_OTLP_HEADERS=

# LangFuse API（レポート/プロンプト取得用）
# ローカル docker-compose を使う場合、HOST 例: http://localhost:3000
LANGFUSE_HOST=
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=

# LangFuse Self-host 初期化（docker-compose 起動時に自動作成）
# 画面で作る代わりに、起動時に組織・プロジェクト・ユーザーを自動作成します。
# すでに初期化済みの場合は効かないことがあるため、その場合は UI で作成するか DB/ボリュームを削除して再起動してください。
#
# 固定キー運用にしたい場合は、下の INIT で指定する Public/Secret と
# LANGFUSE_PUBLIC_KEY / LANGFUSE_SECRET_KEY を同じ値にしてください（LangFuse API タスク用）。
LANGFUSE_INIT_ORG_ID=
LANGFUSE_INIT_ORG_NAME=
LANGFUSE_INIT_PROJECT_ID=
LANGFUSE_INIT_PROJECT_NAME=
LANGFUSE_INIT_PROJECT_PUBLIC_KEY=
LANGFUSE_INIT_PROJECT_SECRET_KEY=
LANGFUSE_INIT_USER_EMAIL=
LANGFUSE_INIT_USER_NAME=
LANGFUSE_INIT_USER_PASSWORD=

# イベントのサイズ
LANGFUSE_MAX_EVENT_SIZE_BYTES=3221225472